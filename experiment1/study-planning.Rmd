---
title: "Causal Support: Stimuli and Task Structure"
author: "Alex Kale"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
library(tibble)
library(ggplot2)
library(ggdist)
library(RColorBrewer)
set.seed(1234)
```

## Overview: Causal support as benchmark for causal induction

The core idea of this study is to see what we can learn by using *causal support*, as defined by [Griffiths and Tenenbaum](https://web.mit.edu/cocosci/Papers/structure-strength-reprint.pdf), as a normative benchmark for causal induction tasks with visualizations, where chart users attempt to reason about the causal structure underlying data.

Following Griffiths and Tenenbaum, we will present participants with scenarios involving two alternative causal explanations for data, represented by directed acyclic graphs (DAGs), and we will ask them to say the probability that one of those graphs vs the other generated a given data set. We will evaluate these elicited probabilities by comparing them to *causal support*, which is the log likelihood ratio of the data given the two alternative models. While this can be extended to use cases with more than two models, we will focus on toy problems for causal induction to learn what we can as a proof of concept for causal support as an evaluation strategy for causal reasoning with visualizations.

In this document, we plan the data and alternative models we will show participants. Our aim is to plan a trial structure and the copy for a crowdsourced experiment. Adapting tasks from Griffiths and Tenenbaum, as well as Wu, we will ask participants to look at two-way tables showing counts of people with and without disease, given the presence or absence of a gene and the presence or absence of treatment. On each trial we, will show a fake data set and ask for a probability judgment.


## Task Scenario: Does treatment reduce the rate of disease? 

The copy for this problem will be: 
*"A company has hired you to help them analyze 18 data sets that theyâ€™ve collected about the impact of different treatments on different diseases. The company knows that a particular gene causes each disease in about 30% of people who have that gene. The company wants your help figuring out whether their experimental treatments have causal effects of protecting against each disease."*

Before we get into generating fake data, we need a way of evaluating the ground truth probability that the treatment is effective. 

### Monte Carlo simulations

To operationalize a normative judgment on this task, we set up a Monte Carlo simulation for each alternative DAG or hypothesis about causal structure. We represent each DAG as a parameterized simulation where we calculate the log likelihood of the data by integrating over a uniform prior on parameter values. Note that unlike Griffiths and Tenenbaum, we are assuming that there is a base rate of the effect (disease) that is not explained by the covariate (gene).

```{r}
# expects data as counts from a two-way table formatted as follows:
#   count_nGnT  - count with disease given gene F and treatment F
#   total_nGnT  - total given gene F and treatment F
#   count_nGT   - count with disease given gene F and treatment T
#   total_nGT   - total given gene F and treatment T
#   count_GnT   - count with disease given gene T and treatment F
#   total_GnT   - total given gene T and treatment F
#   count_GT    - count with disease given gene T and treatment T
#   total_GT    - total given gene T and treatment T
# the boolean treatment_works determines which DAG is simulated
likelihood_from_monte_carlo <- function (count_nGnT, total_nGnT, count_nGT, total_nGT, count_GnT, total_GnT, count_GT, total_GT, treatment_works = TRUE) {
  # define parameters (sample from uniform distribution)
  m <- 10000             # number of simulations
  p_disease <- runif(m)  # base rate of disease due to unknown causes
  p_gene_d <- runif(m)   # probability that gene causes disease
  if (treatment_works) {
    p_treat <- runif(m)  # probability that treatment prevents disease
  } else {
    p_treat <- rep(0, m) # treatment has no effect on disease
  }
  
  
  # calculate counts for each possible outcome in the contingengy table
  counts <- cbind(
    count_nGnT,
    total_nGnT - count_nGnT,
    count_nGT,
    total_nGT - count_nGT,
    count_GnT,
    total_GnT - count_GnT,
    count_GT,
    total_GT - count_GT
  )
  
  # calculate probabilies for each possible outcome in the contingency table
  probs <- cbind(
    p_disease,                                                                           # p(disease|gene F, treatment F)
    (1 - p_disease),                                                                     # p(~disease|gene F, treatment F)
    p_disease*(1 - p_treat),                                                             # p(disease|gene F, treatment T)
    (1 - p_disease) + p_disease*p_treat,                                                 # p(~disease|gene F, treatment T)
    p_gene_d + p_disease - p_gene_d*p_disease,                                           # p(disease|gene T, treatment F)
    (1 - p_gene_d)*(1 - p_disease),                                                      # p(~disease|gene T, treatment F)
    (p_gene_d + p_disease - p_gene_d*p_disease)*(1 - p_treat),                           # p(disease|gene T, treatment T)
    (1 - p_gene_d)*(1 - p_disease) + (p_gene_d + p_disease - p_gene_d*p_disease)*p_treat # p(~disease|gene T, treatment T)
  )
  
  # calculate log likelihood of data for each of m runs of the simulation
  loglik <- rowSums(matrix(rep(counts, m), nrow = m, ncol = 8, byrow = TRUE) * log(probs))
  # normalize by maximum likelihood to make probabilities comparable across Monte Carlo simulations
  # and marginalize over simulated parameter values
  logmax <- max(loglik)
  logscore <- logmax + log(sum(exp(loglik - logmax))) - log(m)
}
```

Now we can generate fake data sets and calculate how much causal support there is for the effectiveness of the treatment. This enables to establish a normative benchmark for responses.


### Trial structure

Lets generate a bunch of stimuli based on a set of parameters. Now we'll add sampling error by drawing events from a binomial distribution, except in the case of the base rate of treatment because we will always present a balanced sample. To be realistic, we'll use the actual base rate of disease in the US in our model, which is lower than any of the values above. 

```{r}
# number of simulated data sets per combination of factors
n_sims <- 2000

# set up manipulations and simulate fake data
stim1_df <- expand.grid(
    p_gene_d = 0.5,                # gene effect on disease (control)
    br_gene = 0.4,                 # base rate of gene (control)
    p_treat = c(0, 0.1, 0.2, 0.4), # treatment effect (4 levels)
    br_treat = 0.5,                # base rate of treatment (control, no noise)
    p_disease = 0.2,               # base rate of disease (control)
    N = c(100, 500, 1000, 1500)    # sample size (4 levels)
  ) %>%
  rowid_to_column("trialIdx") %>%
  rowwise() %>%
  mutate(
    # get a balanced sample of people do and do not receive treatment
    nTreat = round(N*br_treat),  
    nNoTreat = round(N*(1 - br_treat)),
    # sample possible numbers of people in each group who have the gene
    draw = list(seq(from = 1, to = n_sims, by = 1)),
    total_GnT = list(rbinom(n_sims, nNoTreat, br_gene)), # N(gene T, treatment F)
    total_GT = list(rbinom(n_sims, nTreat, br_gene))     # N(gene T, treatment T)
  ) %>%
  unnest(cols = c("draw", "total_GT", "total_GnT")) %>%
  mutate(
    # calculate number of people in each group who DO NOT have the gene for each draw
    total_nGnT = nNoTreat - total_GnT, # N(gene F, treatment F)
    total_nGT = nTreat - total_GT      # N(gene F, treatment T)
  ) %>%
  rowwise() %>%
  mutate(
    count_nGnT = rbinom(1, total_nGnT, p_disease),                                            # N(disease|gene F, treatment F)
    count_nGT = rbinom(1, total_nGT, p_disease*(1 - p_treat)),                                # N(disease|gene F, treatment T)
    count_GnT = rbinom(1, total_GnT, (p_gene_d + p_disease - p_gene_d*p_disease)),            # N(disease|gene T, treatment F)
    count_GT = rbinom(1, total_GT, (p_gene_d + p_disease - p_gene_d*p_disease)*(1 - p_treat)) # N(disease|gene T, treatment T)
  ) %>%
  # drop intermediate calculations
  select(-one_of(c("nTreat", "nNoTreat")))

head(stim1_df)
```

Now, let's calculate causal support for each simulated data set.

```{r}
stim1_df = stim1_df %>%
  rowwise() %>%
  mutate(
    # calculate causal support for each row difference of log likelihoods is a log odds ratio
    causal_support = likelihood_from_monte_carlo(count_nGnT, total_nGnT, count_nGT, total_nGT, count_GnT, total_GnT, count_GT, total_GT, TRUE) - likelihood_from_monte_carlo(count_nGnT, total_nGnT, count_nGT, total_nGT, count_GnT, total_GnT, count_GT, total_GT, FALSE), 
    # convert causal support into normative probability judgment
    ground_truth = plogis(causal_support)
  )
```

While we want our stimuli to reflect natural sampling error, we also want to counterbalance that sampling error within each data condition across participants. In order to do this, we'll reduce our stimulus data from a distribution of draws to a set of quantiles of ground truth causal support that we can sample systematically.

```{r}
# generate a list of probabilities corresponding to a number of quantiles equal to the number of unique data conditions
n_quantiles <- max(stim1_df$trialIdx)
p <- ppoints(n_quantiles)

# generate a dataframe containing quantiles for each data condition
quantiles1_df <- stim1_df %>%
  group_by(trialIdx) %>%
  summarise(
    qIdx = list(seq(from = 1, to = n_quantiles, by = 1)),
    q = list(quantile(causal_support, p))
  )

# filter draws of possible stimuli to include only our quantiles
stim1_df_filtered <- stim1_df %>%
  # first we need to group our stimuli dataframe the same way as our quantile dataframe without loosing any columns
  group_by(trialIdx, p_gene_d, br_gene, p_treat, br_treat, p_disease, N) %>%
  summarise(
    draw = list(draw),
    total_nGnT = list(total_nGnT),
    total_nGT = list(total_nGT),
    total_GnT = list(total_GnT),
    total_GT = list(total_GT),
    count_nGnT = list(count_nGnT),
    count_nGT = list(count_nGT),
    count_GnT = list(count_GnT),
    count_GT = list(count_GT),
    causal_support = list(causal_support),
    ground_truth = list(ground_truth)
  ) %>%
  # join stimuli data with quantiles, and make rows represent data conditions x quantiles
  full_join(quantiles1_df, by = c("trialIdx")) %>%
  unnest(cols = c("qIdx","q")) %>%
  # find the draws that are closest to our quantiles for each data condition
  rowwise() %>%
  mutate(
    draws_diff_from_q = list(lapply(causal_support, function(x) abs(x - q) )),
    which_draw = which.min(unlist(draws_diff_from_q)),
    draw = draw[[which_draw]],
    total_nGnT = total_nGnT[[which_draw]],
    total_nGT = total_nGT[[which_draw]],
    total_GnT = total_GnT[[which_draw]],
    total_GT = total_GT[[which_draw]],
    count_nGnT = count_nGnT[[which_draw]],
    count_nGT = count_nGT[[which_draw]],
    count_GnT = count_GnT[[which_draw]],
    count_GT = count_GT[[which_draw]],
    causal_support = causal_support[[which_draw]],
    ground_truth = ground_truth[[which_draw]]
  ) %>%
  # drop the columns we no longer need at this point
  select(-one_of(c("draw", "which_draw", "q", "draws_diff_from_q"))) 
```

Let's also grab a couple draws to use for attention check and practice trials.

```{r}
# get min and max causal support values 
max_cs <- max(stim1_df$causal_support)
min_cs <- min(stim1_df$causal_support)

# get data frame of catch trials
catch_df <- stim1_df %>%
  filter(causal_support == max_cs || causal_support == min_cs) %>%
  mutate(
    trialIdx = case_when(
      causal_support == max_cs ~ -1, # practice
      causal_support == min_cs ~ -2, # catch
      TRUE                     ~ as.numeric(trialIdx)),
    qIdx = case_when(
      causal_support == max_cs ~ -1, # practice
      causal_support == min_cs ~ -2, # catch
      TRUE                     ~ as.numeric(trialIdx))
  ) %>%
  select(-draw)

# join with filtered dataframe
stim1_df <- bind_rows(stim1_df_filtered, catch_df)
```

Now, let's visualize the ground truth probability that treatment works, which is derived from causal support, as a function of our manipulations to see how difficult our task setup is.

We can look at the trend across trials as a line as before, but now with uncertainty due to simulated sampling error.

```{r}
stim1_df %>% 
  ggplot(aes(x = p_treat, y = ground_truth)) +
  stat_lineribbon(.width = c(0.95, 0.8, 0.5), color = "black") +
  scale_fill_brewer() +
  theme_bw() +
  facet_grid(N ~ .)
```

Alternatively, we can look at quantile dotplots of simulated trials.

```{r}
stim1_df %>% 
  ggplot(aes(x = as.factor(p_treat), y = ground_truth)) +
  stat_dots(position = "dodge", binwidth = 0.04, quantiles = n_quantiles) +
  theme_bw() +
  facet_grid(N ~ .)
```

In both charts, we can see that we are sampling a nice range of the ground truth with this trial structure. 

Let's check that half of these data conditions fall on either side of causal support of 0, ground truth of 0.5. *Finding combinations of `p_treat` and `N` that meet this criterion was a matter of trial and error.*

```{r}
sum(stim1_df$causal_support > 0) / length(stim1_df$causal_support)
```

```{r}
# stim1_df <- read_csv("/Users/kalea/Code/Projects/Temp/causal-support-experiment-interface/app/main/stimdata1.csv")

# set prior for vsups
stim1_df %>% 
  filter(p_treat == 0) %>%
  mutate(
    alpha = mean(count_nGnT + count_nGT + count_GnT + count_GT),
    beta =  mean((total_nGnT - count_nGnT) + (total_nGT - count_nGT) + (total_GnT - count_GnT) + (total_GT - count_GT))
  ) %>%
  group_by(p_treat) %>%
  summarise(
    alpha = mean(alpha),
    beta = mean(beta)
  )

# set maxN for non-interactive colormaps with scales fixed
stim1_df %>% 
  mutate(
    maxN = max(total_nGnT, total_nGT, total_GnT, total_GT)
  ) %>%
  select(maxN) %>%
  max()

# set maxCount for non-interactive bars with scales fixed
stim1_df %>% 
  mutate(
    maxCount = max(count_nGnT, (total_nGnT - count_nGnT), count_nGT, (total_nGT - count_nGT), count_GnT, (total_GnT - count_GnT), count_GT, (total_GT - count_GT))
  ) %>%
  select(maxCount) %>%
  max()

# set maxCount for interactive bars with scales fixed
stim1_df %>% 
  mutate(
    maxCount = max(count_nGnT + count_nGT + count_GnT + count_GT, (total_nGnT - count_nGnT) + (total_nGT - count_nGT) + (total_GnT - count_GnT) +  (total_GT - count_GT))
  ) %>%
  select(maxCount) %>%
  max()

# # export to tableau
# export_df <- stim1_df %>%
#   mutate(
#     .count_nGnT = total_nGnT - count_nGnT,
#     .count_nGT = total_nGT - count_nGT,
#     .count_GnT = total_GnT - count_GnT,
#     .count_GT = total_GT - count_GT
#   ) %>%
#   pivot_longer(cols = c( count_nGnT, .count_nGnT, count_nGT, .count_nGT, count_GnT, .count_GnT, count_GT, .count_GT), names_to = "outcome", values_to = "count") %>%
#   rowwise() %>%
#   mutate(
#     treatment = if_else(outcome == "count_nGT" || outcome == ".count_nGT" || outcome == "count_GT" || outcome == ".count_GT", "Yes", "No"),
#     Gene = if_else(outcome == "count_GnT" || outcome == ".count_GnT" || outcome == "count_GT" || outcome == ".count_GT", "Yes", "No"),
#     disease = if_else(outcome == "count_nGnT" || outcome == "count_nGT" ||  outcome == "count_GnT" || outcome == "count_GT", "Yes", "No")
#   ) %>%
#   uncount(count)
# write_csv(export_df, "stimuli/tidystimdata1.csv")
```


We save this data to generate stimuli during the experiment.

```{r}
# save data as json
# write.csv(stim1_df, "stimuli/stimdata1.csv", quote = FALSE)
```

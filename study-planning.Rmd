---
title: "Causal Support: Stimuli and Task Structure"
author: "Alex Kale"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
```

## Overview: Causal support as benchmark for causal induction

The core idea of this study is to establish *causal support*, as defined by [Griffiths and Tenenbaum](https://web.mit.edu/cocosci/Papers/structure-strength-reprint.pdf), as a normative benchmark for causal induction tasks with visualizations, where chart users attempt to reason about the causal structure underlying data.

Following Griffiths and Tenenbaum, we will present participants with scenarios involving two alternative causal explanations for data, represented by directed acyclic graphs (DAGs), and we will ask them to say the probability that one of those graphs vs the other generated a given data set. We will evaluate these elicited probabilities by comparing them to *causal support*, which is the log likelihood ratio of the data given the two alternative models. While this can be extended to use cases with more than two models, we will focus on toy problems for causal induction to learn what we can as a proof of concept for causal support as an evaluation strategy for causal reasoning with visualizations.

In this document, we plan the data and alternative models we will show participants. Our aim is to plan a trial structure and the copy for a crowdsourced experiment. Adapting tasks from Griffiths and Tenenbaum, as well as Wu, we will ask participants to look at two-way tables showing counts of people with and without cancer, given the presence or absence of a gene and the presence or absence of immunotherapy. On each trial we, will show a fake data set and ask for a probability judgment.


## Problem 1: Does immunotherapy reduce the rate of cancer? 

The copy for this problem will be something like: *"Scientists have found a gene that is known to increase the probability of developing a particular type of cancer. In recent years, scientists have developed an experimental immunotherapy which may reduce the probability of developing this cancer. These data show the number of patients who do and do not develop cancer grouped based on whether or not they have the gene known to cause this cancer and whether or not they have received immunotherapy. Based on the data in the table, what is the probability that the immunotherapy is effective at reducing cancer?"*

Before we get into generating fake data, we need a way of evaluating the ground truth probability that the immunotherapy is effective. 

### Monte Carlo simulations

To operationalize a normative judgment on this task, we set up a Monte Carlo simulation for each alternative DAG or hypothesis about causal structure. We represent each DAG as a parameterized simulation where we calculate the log likelihood of the data by integrating over a uniform prior on parameter values. Note that unlike Griffiths and Tenenbaum, we are assuming that there is a base rate of the effect (cancer) that is not explained by the covariate (gene).

```{r}
# expects data as counts from a two-way table formatted as follows:
#   A   - count with cancer given gene T and immunotherapy T
#   nA  - total given gene T and immunotherapy T
#   B   - count with cancer given gene F and immunotherapy T
#   nB  - total given gene F and immunotherapy T
#   C   - count with cancer given gene T and immunotherapy F
#   nC  - total given gene T and immunotherapy F
#   D   - count with cancer given gene F and immunotherapy F
#   nD  - total given gene F and immunotherapy F
# the boolean immunotherapy_works determines which DAG is simulated
likelihood_from_monte_carlo <- function (A, nA, B, nB, C, nC, D, nD, immunotherapy_works = TRUE) {
  # define parameters (sample from uniform distribution)
  m <- 10000             # number of simulations
  p_cancer <- runif(m)   # base rate of cancer due to unknown causes
  p_gene <- runif(m)     # probability that gene causes cancer
  if (immunotherapy_works) {
    p_immun <- runif(m)  # probability that immunotherapy prevents cancer
  } else {
    p_immun <- rep(0, m) # immunotherapy has no effect on cancer
  }
  
  
  # calculate counts for each possible outcome in the contingengy table
  counts <- cbind(
    A,
    nA - A,
    B,
    nB - B,
    C,
    nC - C,
    D,
    nD - D
  )
  
  # calculate probabilies for each possible outcome in the contingency table
  probs <- cbind(
    (p_gene + p_cancer - p_gene*p_cancer)*(1 - p_immun),                         # p(cancer|gene T, immunotherapy T)
    (1 - p_gene)*(1 - p_cancer) + (p_gene + p_cancer - p_gene*p_cancer)*p_immun, # p(~cancer|gene T, immunotherapy T)
    p_cancer*(1 - p_immun),                                                      # p(cancer|gene F, immunotherapy T)
    (1 - p_cancer) + p_cancer*p_immun,                                           # p(~cancer|gene F, immunotherapy T)
    p_gene + p_cancer - p_gene*p_cancer,                                         # p(cancer|gene T, immunotherapy F)
    (1 - p_gene)*(1 - p_cancer),                                                 # p(~cancer|gene T, immunotherapy F)
    p_cancer,                                                                    # p(cancer|gene F, immunotherapy F)
    (1 - p_cancer)                                                               # p(~cancer|gene F, immunotherapy F)
  )
  
  # calculate log likelihood of data for each of m runs of the simulation
  loglik <- rowSums(matrix(rep(counts, m), nrow = m, ncol = 8, byrow = TRUE) * log(probs))
  # normalize by maximum likelihood to make probabilities comparable across Monte Carlo simulations
  # and marginalize over simulated parameter values
  logmax <- max(loglik)
  logscore <- logmax + log(sum(exp(loglik - logmax))) - log(m)
}
```

Now we can generate fake data sets and calculate how much causal support there is for the effectiveness of the immunotherapy. This enables to establish a normative benchmark for responses.

### Exploring the design space of fake data for stimuli

We're actually going to use the same simulations of data generating processes above to generate a bunch of possible stimuli. We'll assume range of setups which we might expect to influence task difficulty, namely:
 
 - the probability of cancer given the gene, 
 - the base rate for the gene, 
 - the probability that immunotherapy prevents cancer, 
 - the base rate for immunotherapy
 - the probability of cancer due to unexamined causes
 - sample size

This will help us get a sense of the design space for stimuli, so we can choose which of these parameters we want to hold constant or manipulate across trials. For simplicity, we'll assume that these parameters are perfectly represented in the fake data (i.e., we are not simulated sampling error yet).

Here's our fake data.

```{r}
stim_df <- expand.grid(
    p_gene = seq(from = 0.1, to = 0.7, by = 0.2),                      # gene effect
    br_gene = seq(from = 0.05, to = 0.5, by = 0.15),                   # base rate of gene
    p_immun = seq(from = 0, to = 0.9, by = 0.15),                      # immunotherapy effect 
    br_immun = seq(from = 0.05, to = 0.5, by = 0.15),                  # base rate of immunotherapy
    p_cancer = c(0.01, 0.05, 0.1),                                     # base rate of cancer
    N = c(100, 5000)                                                   # small and large sample size
  ) %>%
  mutate(
    nA = round(N*br_gene*br_immun),                                    # N(gene T, immunotherapy T)
    A = round(nA*(p_gene + p_cancer - p_gene*p_cancer)*(1 - p_immun)), # N(cancer|gene T, immunotherapy T)
    nB = round(N*(1 - br_gene)*br_immun),                              # N(gene F, immunotherapy T)
    B = round(nB*p_cancer*(1 - p_immun)),                              # N(cancer|gene F, immunotherapy T)
    nC = round(N*br_gene*(1 - br_immun)),                              # N(gene T, immunotherapy F)
    C = round(nC*(p_gene + p_cancer - p_gene*p_cancer)),               # N(cancer|gene T, immunotherapy F)
    nD = round(N*(1 - br_gene)*(1 - br_immun)),                        # N(gene F, immunotherapy F)
    D = round(nD*p_cancer)                                             # N(cancer|gene F, immunotherapy F)
  )

head(stim_df)
```

Now, let's apply our version of Griffiths and Tenenbaum's causal support calculation to the data in each row, where each row represents a possible data generating process without noise.

```{r}
stim_df = stim_df %>%
  rowwise() %>%
  mutate(
    # calculate causal support for each row difference of log likelihoods is a log odds ratio
    causal_support = likelihood_from_monte_carlo(A, nA, B, nB, C, nC, D, nD, TRUE) - likelihood_from_monte_carlo(A, nA, B, nB, C, nC, D, nD, FALSE), 
    # convert causal support into normative probability judgment
    ground_truth = plogis(causal_support)
  )
```

Let's visualize the ground truth suggested by causal support as a function of some of these manipulations.

To start, let's see how sample size and the base rates of the gene and immunotherapy impact the ability to detect various effects of immunotherapy, holding the effect of the gene and the base rate of cancer constant.

```{r}
stim_df %>% 
  filter(p_gene == 0.1, p_cancer == 0.01) %>%
  ggplot(aes(x = p_immun, y = ground_truth, color = as.factor(N))) +
  geom_line() +
  theme_bw() +
  facet_grid(br_gene ~ br_immun)
```

We can see that the normative response is more certain (closer to 0 or 1) when sample size is high (teal line), regardless of other manipulations. This is consistent with what we might expect. *Manipulating sample size is a good way to manipulate task difficulty.* 

Additionally, *manipulating the effect of the immunotherapy is an obvious way to change the task difficulty.*

We can also see that the normative response gets more certain when the base rate of immunotherapy (columns) is high. This also makes intuitive sense because the more people we give the immunotherapy to, the more information we have to assess its effectiveness. *We may want to hold the base rate of immunotherapy constant by always presenting a balanced sample.*

It seems like the base rate of the gene (rows) has less impact on task difficulty, except when the effect of immunotherapy (x-axis) is small, suggesting that *maybe we want to hold the base rate of the gene constant.*

Now, let's modify the query above to see how the sample size, the effect of the gene, and the base rate of cancer impact the ability to detect various effects of immunotherapy, holding the base rates of the gene and immunotherapy constant.

```{r}
stim_df %>% 
  filter(round(10*br_gene)/10 == 0.2, round(10*br_immun)/10 == 0.5) %>%
  ggplot(aes(x = p_immun, y = ground_truth, color = as.factor(N))) +
  geom_line() +
  theme_bw() +
  facet_grid(p_gene ~ p_cancer)
```

We can see that the normative response may be slightly more certain when the effect of the gene (rows) is larger, but the impacts are small and don't seem to be monotonic. Griffiths and Tenenbaum talk about this as a unique prediction of causal support compared to other models of causal induction. *We would probably only want to manipulate the effect of the gene if we think that predicting this monotonacity is important to our findings.*

We can also see that the normative response is hardly impacted by the base rate of cancer due to unexplained causes (columns). *Maybe we want to hold the base rate of cancer constant.* 

#### Summary of data manipulations

Manipulating the sample size and the effect of immunotherapy seem like good ways to change task difficulty across trials.

To keep things simple, we probably want to present a balanced sample on each trial (i.e., an equal number of people who have vs haven't received the immunotherapy).

Above, I've suggested that we could probably hold the following variables constant: base rate of the gene, effect of the gene, and base rate of cancer. However, if we want to sell the idea that each trial is asking about a different gene and type of cancer, we might want to add a small amount of random noise to these fixed values on each trial. We aren't interested in the effect of these values, but small variations won't impact causal support very much and might make the task scenario more believeable.


## Problem 2: Does the gene that causes cancer also reduce the effectiveness of immunotherapy?

The copy for this problem will be something like: *"Scientists have found a gene that is known to increase the probability of developing a particular type of cancer. Scientists have also developed an immunotherapy which is known to reduce the probability of developing this cancer. However, in recent years, some scientists have hypothesized that the same gene known to cause cancer may also reduce the effectiveness of the immunotherapy. These data show the number of patients who do and do not develop cancer grouped based on whether or not they have the gene known to cause this cancer and whether or not they have received immunotherapy. Based on the data in the table, what is the probability that the gene reduces the is effectiveness of the immunotherapy?"*

### Monte Carlo simulation

We'll need to set up an additional Monte Carlo simulation to represent the case where there is a confounding effect of the gene on an immunotherapy that is known to be effective...

